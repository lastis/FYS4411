\documentclass[twocolumns, a4paper,11pt,fleqn]{extarticle}
\usepackage[english]{babel} 
\usepackage[latin1]{inputenc} 
\usepackage{times}			% Default times font style
\usepackage[T1]{fontenc} 	% Font encoding
\usepackage{amsmath} 		% Math package
\usepackage{mathtools} 		% Adds the declare paired 
							% delimeter command to make costom \abs and \norm
\usepackage{breqn}		 	% Adds dmath environment for automated brakeline
\usepackage{xfrac}			% Adds slanted fractions (sfrac)
\usepackage{cancel}			% Adds the cancel command, a slash through the symbol(s)
\usepackage{tabularx}		% Adds adjustable width on tabulars
\usepackage{cuted}			% Adds the strip command, pagewidth text in a twocolumn
							% environment.  
\usepackage{hyperref}
\usepackage[a4paper, margin=0.6in]{geometry}


% Alghorithm packages:
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

% Start custom \abs \norm 
\DeclarePairedDelimiter\abs{\lvert}{\rvert}%
\DeclarePairedDelimiter\norm{\lVert}{\rVert}%
% Swap the definition of \abs* and \norm*, so that \abs
% and \norm resizes the size of the brackets, and the 
% starred version does not.
\makeatletter
\let\oldabs\abs
\def\abs{\@ifstar{\oldabs}{\oldabs*}}
%
\let\oldnorm\norm
\def\norm{\@ifstar{\oldnorm}{\oldnorm*}}
\makeatother
% End custom \abs \norm 

\usepackage{titlesec}
\titleformat{\section}[block]{\bfseries\filcenter}{\thesection}{1em}{\uppercase}
\titleformat{\subsection}[hang]{\bfseries\filcenter}{\thesubsection}{1em}{}
\titleformat{\subsubsection}[hang]{\bfseries\filcenter}{\thesubsubsection}{1em}{}

% TODO: Put comments on this section.
\newcommand{\eq}[1]{{\small\begin{align*}#1\end{align*}}}
\newcommand{\equ}[1]{{\small\begin{align}#1\end{align}}}
\newcommand{\mat}[1]{\begin{matrix}#1\end{matrix}}
\newcommand{\pmat}[1]{\begin{pmatrix}#1\end{pmatrix}}
\newcommand{\bmat}[1]{\begin{bmatrix}#1\end{bmatrix}}
\newcommand{\vmat}[1]{\begin{vmatrix}#1\end{vmatrix}}
\newcommand{\ket}[1]{|#1\rangle}
\newcommand{\bra}[1]{\langle#1|}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
\newcommand{\Int}[4]{\int_{#1}^{#2} \! \mathrm{d}#3 \, #4}
\renewcommand\vec[1]{\boldsymbol{\mathbf{#1}}}
\newcommand{\OP}[1]{\mathbf{\widehat{#1}}}
\newcommand{\op}[1]{\hat{#1}}
\newcommand{\unit}[1]{\mathbf{\hat{#1}}}
\renewcommand{\thesection}{\Roman{section}}
\renewcommand{\thesubsection}{\Alph{subsection}.}
\renewcommand{\thesubsubsection}{\roman{subsubsection}.}

\title{}

\begin{document}

\twocolumn[{%
 \centering
 {\bfseries\large Variational Monte-Carlo Simulations of Atomic Systems}
 \\[1em]
 \normalsize Daniel Marelius Bj\o rnstad and Alexander Fleischer
 \\
 \small\url{https://github.com/lastis/FYS4411}
  \begin{abstract}
    This is where the abstract goes. Write something smrt here.
  \end{abstract}
 \\[3em] % some more space after the title part
}]

\section{Introduction}

To evaluate the results of the numerical methods, we investigated the possibility
of finding a closed-form solution of the ground-state energy 
using the Variational Principle.

\section{Methods}
\subsection{The Quantum Mechanical System}
The Helium atom consists of two electrons orbiting a nucleus,
where the distance between electron 1 and the nucleus,
and electron 2 and the nucleus are labeled as
$r_1 = \sqrt{x_1^2 + y_1^2 + z_1^2}$ 
and $r_2 = \sqrt{x_2^2 + y_2^2 + z_2^2}$ in cartesian coordinates.

The total potential energy of the system is modelled as
{\small
\eq{
    V(r_1,r_2)=-\frac{2}{r_1}-\frac{2}{r_2}+\frac{1}{r_{12}}
}}%
where the interaction between each electron and the nucleus
is given by the two first terms. 
The mutual electron-electron repulsion is given by the last.
The distance between two electrons is $r_{ij}=|\vec r_j-\vec r_i|$.

The \textit{Hamiltonian} of the system is thus
\eq{
    \OP H = -\frac{\nabla_1 ^2}{2} -\frac{\nabla_2 ^2}{2}
    -\frac{2}{r_1}-\frac{2}{r_2}+\frac{1}{r_{12}}
}
scaled to \textit{atomic units} (a.u.).

This is based on the simplified, analytically solvable, system for the 
Hydrogen atom, where the Hamiltonian is
\eq{
  \OP H = \OP K + \OP V = -\frac{\hbar^2}{2m_e}\op \nabla^2 - \frac{e^2}{4\pi \epsilon_0 r}
}
with $e$ as the electron charge and $m_e$ as the mass of the electron.

This operator satisfies the \textit{time-independent Schr\"odinger Equation}
\eq{
  \OP H \ket{\psi} = E \ket{\psi}
}
where $E$ is the \textit{energy eigenvalue} and $\psi$ is the \textit{eigenstate} of the system.

For a Hydrogen-like quantum mechanical system, we can model the general
Hamiltonian of an atom as
\eq{
  \OP H
  &=\sum_i (\op k_i + \op v_i)  + \sum_{i<j} \op v_{ij}\\
  &= -\sum_{i=1}^N\bigg[
    \frac{\op\nabla_i^2}{2} + \frac{Z}{r_i}\bigg] 
  + \sum_{i=1}^{N-1}\sum_{j=i+1}^N\frac{1}{r_{ij}} \numberthis\label{ham}
}
Here $Z$ is the nuclear charge, 
and we have another sum for all the electron/electron repulsions.

We can add to this model by setting up a system of two atoms,
a \textit{diatomic molecule}, which gives us a Hamiltonian on the form
\eq{
  \OP H = -\sum_{i=1}^N\bigg[
    \frac{\op\nabla_i^2}{2} + \frac{Z_1}{r_{ip1}} + \frac{Z_2}{r_{ip2}}\bigg] 
    + \sum_{i=1}^{N-1}\sum_{j=i+1}^N\frac{1}{r_{ij}} + \frac{Z_1 Z_2}{R}
}

\subsection{Slater Determinants}
The Hamiltonian (\ref{ham}) introduced in the last section is invariant
when you interchange two particles, and since electrons are \textit{fermions},
it is required that the wave function is antisymmetric.

In practice, this means that for a system of two particles, $1$ and $2$, described by the
wave functions $\psi_a$ and $\psi_b$, we must have a total wave function on the form
\equ{
  \psi^{1,2} = \psi_a^1 \psi_b^2 - \psi_b^1 \psi_a^2\label{wavfunc}
}
This is a result that follows from the fact that particles are indistinguishable,
and the minus sign comes from the antisymmetry condition.
An exchange operator $\OP P$ acting on an antisymmetric wave function,
will therefore change the sign, thus the wave function is an eigenfunction
of $\OP P$ with eigenvalue $p=-1$.

For bosons however, the sign is positive. This means that 
they do not obey the \textit{Pauli principle},
stating that two particles can not occupy the same state, 
which would imply $\psi^{1,2}=0$.

If we rewrite equation (\ref{wavfunc}), we see that this is actually a determinant
\eq{
  \psi^{1,2} = \vmat{\psi_a^1&\psi_b^1\\ \psi_a^2&\psi_b^2}
}
that can be generallized to the $N$-particle case as
\equ{
  \psi(\vec r_1, \dots, \vec r_N) 
  = \frac{1}{\sqrt{N!}}\vmat{\psi_1^1&\cdots&\psi_N^1\\ 
  \vdots & \ddots & \vdots \\ 
  \psi_1^N& \cdots &\psi_N^N}\label{slaterdet}
}
These Slater determinants obey exchange operations, since switching
two rows of the determinant changes the sign.
In our project we will omit the factor in front of the determinant,
as the important part is proportionality, and we will see later that constants get cancelled.

In this project, we are studying spin-$\frac{1}{2}$ particles,
and we must address this problem in the Slater determinants we will use.
The electrons have either spin $\uparrow$ or $\downarrow$,
so our determinant in (\ref{slaterdet}) 
have elements labeled $\uparrow$ or $\downarrow$.
However, we must also label them by their atomic orbitals,
so an element of the determinant will have the form
\eq{
  \phi_{j\sigma}(\vec r_i) = \phi_{j\sigma}^i
}
where $j$ is the atomic orbital (1s, 2s, 2p in this project), $\sigma$ is the spin,
and $i$ is the particle number.
Determinants of matrices with elements like that for Helium, Beryllium and Neon, 
are unfortunately zero, 
since they are independent of spin
(two and two columns would be equal).
This can be bypassed by writing the determinant $\abs*{\op D}$ as a product of two smaller ones
for each spin\footnote{Morten, 519-520}, since
\eq{
  \psi_D = \abs*{\op D} \propto \abs*{\op D}_{\uparrow} \abs*{\op D}_{\downarrow}
}
By doing this, the wave function
will lose its antisymmetry when interchanging particles,
but it doesn't affect the expectation values.

For Helium,
we write the wave function as a product of the (reduced) $1\times1$ matrices
to simplify the function. Therefore
\eq{
  \psi_D^{He} = \phi_{1s}(\vec r_1) \phi_{1s}(\vec r_2)
}

For Beryllium (four electrons), the corresponding Slater determinant is
\eq{
  \psi_D^{Be} 
    &=\vmat{
    \phi_{1s\uparrow}^1&\phi_{1s\uparrow}^2
      &\phi_{1s\uparrow}^3&\phi_{1s\uparrow}^4\\
    \phi_{1s\downarrow}^1&\phi_{1s\downarrow}^2
      &\phi_{1s\downarrow}^3&\phi_{1s\downarrow}^4\\
    \phi_{2s\uparrow}^1&\phi_{2s\uparrow}^2
      &\phi_{2s\uparrow}^3&\phi_{2s\uparrow}^4\\
    \phi_{2s\downarrow}^1&\phi_{2s\downarrow}^3
      &\phi_{2s\downarrow}^2&\phi_{2s\downarrow}^4
    }\\
    &=\vmat{
    \phi_{1s\uparrow}^1&\phi_{1s\uparrow}^2\\
    \phi_{2s\uparrow}^1&\phi_{2s\uparrow}^2\\
    }
    \vmat{
    \phi_{1s\downarrow}^3&\phi_{1s\downarrow}^4\\
    \phi_{2s\downarrow}^3&\phi_{2s\downarrow}^4\\
    }
}
and finally for Neon (ten electrons), 
the spin $\uparrow$ part (and similarly for $\downarrow$)
\eq{
  \abs*{\op D}_{\uparrow}^{Ne} 
    &=\vmat{
    \phi_{1s\uparrow}^1&\phi_{1s\uparrow}^2
      &\phi_{1s\uparrow}^3&\phi_{1s\uparrow}^4&\phi_{1s\uparrow}^5\\
    \phi_{2s\uparrow}^1&\phi_{2s\uparrow}^2
      &\phi_{2s\uparrow}^3&\phi_{2s\uparrow}^4&\phi_{2s\uparrow}^5\\
    \phi_{2p_x\uparrow}^1&\phi_{2p_x\uparrow}^2
      &\phi_{2p_x\uparrow}^3&\phi_{2p_x\uparrow}^4&\phi_{2p_x\uparrow}^5\\
    \phi_{2p_y\uparrow}^1&\phi_{2p_y\uparrow}^2
      &\phi_{2p_y\uparrow}^3&\phi_{2p_y\uparrow}^4&\phi_{2p_y\uparrow}^5\\
    \phi_{2p_z\uparrow}^1&\phi_{2p_z\uparrow}^2
      &\phi_{2p_z\uparrow}^3&\phi_{2p_z\uparrow}^4&\phi_{2p_z\uparrow}^5
    }
}
Here we have used equality instead of proportionality, since these are the actual
wave functions we will use.

\subsection{The Variational Principle}
The Variation Principle states that if we have a Hamiltonian
$\OP H$ and a trial wavefunction $\psi_{T}$,
an upper bound for the ground state energy $E_0$ is given by
equation (\ref{E0var}). 
\equ{
	E_0 \leq
	\langle H \rangle =
	\frac{\Int{}{}{\vec R}{\psi_T^*(\vec R) \OP{H}(\vec R) \psi_T(\vec R)}}
	{\Int{}{}{\vec R}{\psi_T^*(\vec R) \psi_T(\vec R)}}\label{E0var}
}
To find such a wave function, we expand it in the eigenstates of
the Hamiltonian (since they form a complete set) as follows
\eq{
  \psi_T(\vec R) = \sum_i c_i \psi_i(\vec R)
}
and given that they are normalized, we get
\eq{
  E_0 \leq
  \frac{\sum_{i,j}c_m^*c_n\Int{}{}{\vec R}{\psi_m^*(\vec R) \OP{H}(\vec R) \psi_n(\vec R)}}
	{\sum_{m,n}c_m^*c_n\Int{}{}{\vec R}{\psi_m^*(\vec R) \psi_n(\vec R)}}\label{E0var}
  = \frac{\sum_n \abs*{c_n}^2 E_n}{\sum_n \abs*{c_n}^2}
}
since $E_0 = E_0 \sum_n \abs*{c_n}^2 \leq \sum_n E_n \abs*{c_n}^2 $

The key to the variational principle is to find suitable trial wave functions
that live in the same Hilbert space as the Hamiltonian.
Given a trial wave function, we can then vary som parameters 
$\vec \alpha = (\alpha,\,\beta,\,\dots)$ to optimalize the function,
and the energy value $E_T$.

Another (analytical) quantity that we want to calculate, is the \textit{local energy}
\eq{
  E_L(\vec R, \vec \alpha) = \frac{1}{\psi_T(\vec R, \vec \alpha)} \OP H \psi_T(\vec R, \vec \alpha)
}
which together with (\ref{E0var}) yields

\begin{equation}
  \langle H \rangle 
  = \frac{\Int{}{}{\vec R}{E_L \abs*{\psi_T}^2}}
	{\Int{}{}{\vec R}{\abs*{\psi_T}^2}} \label{exp}
\end{equation}


\subsection{Variational Monte Carlo (VMC)}
The integrals to be solved in the variational method,
does not scale well with traditional integral methods when 
increasing the number of particles and dimensions and using 
more complex wave functions .
Therefore, we introduce the \textit{brute-force Monte Carlo method}
to solve the integrals.

We define
\eq{
  P(\vec R) \equiv \frac{\abs*{\psi_T}^2}{\Int{}{}{\vec R}{\abs*{\psi_T}^2}}
}
and can then rewrite the integral in (\ref{exp}), and approximate it as
\eq{
  \Int{}{}{\vec R}{E_L P(\vec R)} \approx \frac{1}{N}\sum_{i=1}^N E_L P(\vec R)
}
Here $N$ is the number of \textit{Monte Carlo samples}.
An outline of the algorithm can be seen in Algorithm \ref{algo:vmc}.

\begin{algorithm}[H]
	\caption{VMC Algorithm}\label{algo:vmc}
  \begin{algorithmic}[1]
    \Procedure{Initialization}{}
      \State{Set a fixed number of MC steps.}
      \State{Choose initial position $\vec R$ and variational
            
            parameters $\boldsymbol\alpha$.}
      \State{Calculate $|\psi_T(\vec R)|^2$.}
    \EndProcedure
    \Procedure{Initialize energy and variance and start the MC calculation}{}
      \State{Find the trial position $\vec R' =\vec R + \delta\times r $,
      
            where $r\in [0,1]$ is randomly selected.}
      \State{Use the Metropolis algorithm to determine if the
      
            move $w =\frac{P(\vec R')}{P(\vec R)}$ is accepted or rejected.}
      \State{Given that the move is accepted, set $\vec R = \vec R'$.}
      \State{Update averages.}
    \EndProcedure
    \Procedure{Compute final averages}{}
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

\subsection{The Metropolis Algorithm}
In the VMC algorithm (Algorithm \ref{algo:vmc}),
one of the steps is to perform the Metropolis algorithm to determine wheter or not
a step is rejected or accepted.

The Metropolis algorithm samples a normalized probability distribution
by a stochastic process. In other words, it is a method for simultaing
random walks, which we can use to do brute-force Monte Carlo computations.
The algorithm uses \textit{Markov chains}, where each state $i$,
has some probability of going to another state $j$.
Each state is only dependent on the last state it was in.

Define $P^{(n)}_i$ as the probability for finding the system in state $i$
at some step $n$. This probability is given by the sum of the probability of
previously being in a state $j$, transitioning to $i$, $T_{j\rightarrow i}$,
and the probability of rejecting the transition to another state $j$,
$1-A_{i\rightarrow j}$.
Where $A$ is the acceptance ratio

This results in
\eq{
  P_{i}^{(n)} = 
  \sum_j \left[
  P_{j}^{(n-1)} T_{j\rightarrow i} A_{j\rightarrow i}-
  P_{i}^{(n-1)} T_{i\rightarrow j} A_{i\rightarrow j}
  \right]
}
since the probability of making a transition must be $1$, $\sum_j T_{i\rightarrow j}$.


See Algorithm \ref{algo:metro} for an outline of the Metropolis algorithm.

\begin{algorithm}[H]
	\caption{Metropolis Algorithm}\label{algo:metro}
  \begin{algorithmic}[1]
    \Procedure{Metropolis test}{}
      \State{Sample a possible new state $j$,
       
      with a probability $T_{i\rightarrow j}$.}
      \State{With probability $A_{i\rightarrow j}$, accept $j$ as a new state.}
      \State{Set it as the new sample.}
      \State{The move is rejected with probability $1-A_{i\rightarrow j}$.}
      \State{Set $i$ as the sample again.}
    \EndProcedure
  \end{algorithmic}
\end{algorithm}























\clearpage
{\Huge Everything below this point is not revised, or will be removed.}

\subsection{The Metropolis Algorithm}
The Metropolis algorithm samples a normalized probability distribution
by a stochastic process. In other words, it is a method for simultaing
random walks, which we can use to do brute-force Monte Carlo computations.

Define $P^{(n)}_i$ as the probability for finding the system in state $i$
at some step $n$.

\begin{itemize}
	\item Sample a possible new state $j$ with a probability $T_{i\rightarrow j}$.
	\item With probability $A_{i\rightarrow j}$, accept $j$ as a new state.
	Set it as the new sample. The move is rejected with probability $1-A_{i\rightarrow j}$.
	set $i$ as the sample again.
\end{itemize}


\subsection{Importance Sampling}
A random walker is the most efficient way to sample where the
wave function is large. To increase this, we can implement importance
sampling, where the walk in space is affected by the trial wave function. 

The results are based on the Fokker-Planck equation, and the Langevin 
equation. This makes the step look similar to a diffusion process
where the new position is given by
\begin{align*}
y = x + DF(x) \delta t + \xi \sqrt{\Delta t}.
\end{align*}

where $\xi $ is a gaussian random variable, and $\Delta t$ is a chosen timestep.
In atomic units, $D$ is $1/2$, and in our plots $\Delta t = 0.01$. 

An important part of this result is that the walker is affected by $F(x)$
which contains the trial wavefunction. This has been named the \textit{quantum 
force}. 

\begin{align*}
\vec F = 2\frac{1}{\Psi_T}\nabla \Psi_T. 
\end{align*}

This also has the result of changing the random number check in the 
Metropolis algorithm from:
$q(y,x) = |\Psi_T(y)|^2/|\Psi_T(x)|^2$ to: 
\[
q(y,x) = \frac{G(x,y,\Delta t)|\Psi_T(y)|^2}{G(y,x,\Delta t)|\Psi_T(x)|^2}.
\]

Where G is the Green function given by,

\eq{
  G(y,x,\Delta t) =  \frac{1}{(4\pi D\Delta t)^{3N/2}}\\ \cdot \exp{\left(-(y-x-D\Delta t F(x))^2/4D\Delta t\right)}.
}

\subsection{Statistical Analysis}
The MC calculation are a set of computational \textit{experiments}, 
with statistical errors. In the experiments we are interested in the mean
value of the ground energies and the density distribution. The 
individual samples are not as interesting to us and we would rather like
to look in the variance of the mean value. 

	The variance of the mean value is closely connected with the correlation
in the individual samples. This can be shown mathematically, but the result
is this:
\eq{
\sigma^2(m) &= \frac{1}{n^2}\sum_{i,j=1}^{n} \mathrm{Cov}(x_i,x_j)
}

Both our random walker and walking with importance sampling gives correlated
samples. In our case, blocking is the technique of finding out have many steps
the walker has to go to be as uncorrelated as possible with it's first step.
If we then plot the variance in mean as a function of block size we 
will see that the variance reaches a plateau. 

This plateau means that increasing the sample length will no longer
change the variance in the mean significantly. This makes us able to more easily calculate 
variance in the mean because we know how short block sizes we can use. 
This is used to make the standard deviation interval around our densities. 


\subsubsection{Blocking Implementation}

\begin{itemize}
    \item Compute MC calculation, store samples in array.
    \item Loop over a set of block sizes $n_b$.
    \item For each $n_b$, calculate the mean of the block
        and store these values in a new array.
    \item Take the mean and variance of this array.
    \item Store results.
\end{itemize}

\subsection{The Trial Wavefunctions for Helium}

To conclude if the computational methods are implemented correctly,
we should check that the results are reasonable. We do this by
finding a mathematical approximation of the closed form expression.

%% The closed-form expression.
Given the trial wavefunction $\psi_T (\vec R, \boldsymbol\alpha)$, 
we define a new quantity
{\small
\eq{
  E_L = \frac{1}{\psi_T}\OP H \psi_T
}}%
where $\boldsymbol\alpha$ is a set of variational parameters.
$E_{L1}$ is called the local energy

\subsubsection{The first trial wavefunction}
We first model the variational solution with a trial function of one
variation parameter $\alpha$. It has the form
{\small
\eq{
\psi_{T1}({\bf r_1},{\bf r_2}) = 
   \exp{\left(-\alpha(r_1+r_2)\right)}
}}%

The only part of the operator $\OP H$ that affects the wavefunction
are the Laplace operators.

Since $\psi_{T1}$ is only spatially dependent on $r_1$ and $r_2$,
the Laplaces of $\psi_{T1}$ reduces to
{\small
\eq{
  \nabla_i^2 \psi_{T1} = \bigg( \frac{\partial^2}{\partial r_i^2} 
    + \frac{2}{r_i} \frac{\partial}{\partial r_i} \bigg) \psi_{T1}
    = \bigg( \alpha^2 -\alpha\frac{2}{r_i}  \bigg)\psi_{T1}
}}%
for $i = 1,\;2$, since
{\small
\eq{
  \frac{\partial}{\partial r_i} e^{-\alpha (r_1+r_2)}
    &= -\alpha e^{-\alpha (r_1+r_2)}\\
\frac{\partial^2}{\partial r_i^2} e^{-\alpha (r_1+r_2)}
    &= \alpha^2 e^{-\alpha (r_1+r_2)}
}}%
This gives us the following trial energy
{\small
\eq{
  E_{L1}&=\frac{1}{\psi_{T1}}\bigg( -\alpha^2 
  +\alpha\bigg( \frac{1}{r_1}+\frac{1}{r_1}  \bigg)
    -\frac{2}{r_1}-\frac{2}{r_2} + \frac{1}{r_{12}}
    \bigg)\psi_{T1}\\
  &=(\alpha-2)\bigg( \frac{1}{r_1}+\frac{1}{r_2} \bigg)
    +\frac{1}{r_{12}}-\alpha^2
}}%
The $2$ in the $\alpha-2$ term is the number of protons, Z.

\subsubsection{The second trial wavefunction}
To approximate the closed-form solution even better,
we assume another trial wavefunction based on $\psi_{T1}$, namely
{\small
\eq{
  \psi_{T2} ({\bf r_1},{\bf r_2}, {\bf r_{12}})
    =\exp{\left(-\alpha(r_1+r_2)\right)}
    \exp{\left(\frac{r_{12}}{2(1+\beta r_{12})}\right)}
}}%
The second part is dependent on the distance between the
electrons, and is called the correlation part,
which accounts for the effect between the electrons.

One can then in the same way as for $\psi_{T1}$ calculate
the local energy. The correlations part will give us some trouble
when we try to calculate the Laplacian. This is due to
the distance between $\vec r_1$ and $\vec r_2$, since this quantity
is dependent on the angles $\varphi$ and $\theta$.
It has the form
{\small
\eq{
	E_{L2} = E_{L1}+\frac{1}{2(1+\beta r_{12})^2}
	\bigg(\frac{\alpha(r_1+r_2)}{r_{12}}(1-
	\frac{\mathbf{r}_1^T\mathbf{r}_2}{r_1r_2})\\
	-\frac{1}{2(1+\beta r_{12})^2}-\frac{2}{r_{12}}+
	\frac{2\beta}{1+\beta r_{12}}\bigg)
}}%

\subsection{The Trial Wavefunction for Beryllium}
We can use a trial wavefunction on the same form as for
Hydrogen and Helium

{\small
\eq{
	\psi_{T}({\bf r_1},{\bf r_2}, {\bf r_3}, {\bf r_4}) &= 
 	Det\left(\phi_{1}({\bf r_1}),\phi_{2}({\bf r_2}),
	\phi_{3}({\bf r_3}),\phi_{4}({\bf r_4})\right)\\ &\cdot
   	\prod_{i<j}^{4}\exp{\left(\frac{r_{ij}}{2(1+\beta r_{ij})}\right)}
}}%

where we approximate the Slater determinant \textit{Det} as
{\small
\eq{
	\psi_{T}({\bf r_1},{\bf r_2}, {\bf r_3}, {\bf r_4})&\propto 
	\left(\phi_{1s}({\bf r_1})\phi_{2s}({\bf r_2})-\phi_{1s}({\bf r_2})
	\phi_{2s}({\bf r_1})\right)\\
	&\cdot\left(\phi_{1s}({\bf r_3})\phi_{2s}({\bf r_4})
	-\phi_{1s}({\bf r_4})\phi_{2s}({\bf r_3})\right)
}}%
where the hydrogenic wavefunctions for the two spin orbitals
are given by
{\small\eq{
\phi_{1s}({\bf r_i}) = e^{-\alpha r_i}
}} and
{\small\eq{
\phi_{2s}({\bf r_i}) = \left(1-\alpha r_i/2\right)e^{-\alpha r_i/2}
}}

\subsection{Onebody Density and Charge Density}
The one-body density is computed from the form 
{\small
\eq{
	\rho(\vec R) = |\psi(\vec R)|^2
}}%

This is implemented as NOTE: ... in our program. 

\subsection{Implementation}
The methods described above are implemented in an object oriented C++ program
which is simple to use, and does not have any dependencies. 

Most of the code is contained in the class VMCSolver.cpp and VMCSolver.h. 
These were created to contain the full system and parameters for a single run. 

To start a simulation one must instantiate the solver and 
initialize the system, either by file and/or manually. After this
the integration can be run and all data will be contained in the solver object.
The last step is to collect data from the solver. 

All plot data are generated by individual programs using the mentioned solver. 
Plots are generated using python. 


\subsection{Trial Wavefunctions}

The trial wavefunction of Beryllium can be written as a product of a Slater determinant
part and a correlation part on the form
\equ{
  \psi_{T}(\vec r_1, \vec r_2, \vec r_3, \vec r_4) = \psi_{D}\psi_{C} \label{psiT}
}
where the Slater determinant is
\equ{
  \psi_D &= Det\left(\phi_{1}(\vec r_1),\phi_{2}(\vec r_2),
    \phi_{3}(\vec r_3),\phi_{4}(\vec r_4)\right) \label{psiD}\\
  &= \left(\phi_{1s}^1\phi_{2s}^2
    -\phi_{1s}^2\phi_{2s}^1\right)
    \left(\phi_{1s}^3\phi_{2s}^4
    -\phi_{1s}^4\phi_{2s}^3\right)\nonumber
}
and the correlation part is
\equ{
  \psi_C = \prod_{i<j}^{4} g_{ij}
   =\prod_{i<j}^{4}\exp{\left(\frac{ar_{ij}}{1+\beta r_{ij}}\right)} \label{psiC}
}
Here $\phi_i(\vec r_i)$ are the hydrogen-like wavefunctions. They are given by
the $1s$ and $2s$ orbital parts
\eq{                                                               
  \phi_{1s}^i &= e^{-\alpha r_i}\\
  \phi_{2s}^i &= \left(1-\alpha r_i/2\right)e^{-\alpha r_i/2}
}
which are dependent on the cartesian positions $\vec r_i = (x_i,y_i,z_i)$. 
The relative distance between two particles is
\eq{
  r_{ij} = \abs{\vec r_j - \vec r_i} = \sqrt{(x_j-x_i)^2+(y_j-y_i)^2+(z_j-z_i)^2}
}
and obviously $r_{ij}=r_{ji}$.

We want to determine the local energy $E_L$ to approximate
the ground state energy of the atom.
The general expression for the local energy is
\eq{
  E_L = \frac{1}{\psi_T (\vec R)}\OP H \psi_T (\vec R) 
}
and the Hamiltonian can generally be described as a sum of the contributions
to the potential energy by the electron-electron repulsion and the nucleus-electron interaction, as well as the kinetic energy. This gives us a Hamiltonian
for $N$ particles on the form
\eq{
  \OP H &= \OP K + \OP V \\
  &=\sum_i (\op k_i + \op v_i)  + \sum_{i<j} \op v_{ij}\\
  &= -\sum_{i=1}^N\bigg[
    \frac{\op\nabla_i^2}{2} + \frac{Z}{r_i}\bigg] 
  + \sum_{i=1}^{N-1}\sum_{j=i+1}^N\frac{1}{r_{ij}}
}
Where $Z$ is the atomic number.

From this expression, it's clear that $\OP K$ is the only operator that changes the
trial wavefunction when we calculate the local energy. Therefore, we must calculate the
following quantities
\eq{
  \frac{1}{\psi_T}\op k_i \psi_T = -\frac{1}{2}\frac{\op\nabla_i^2 \psi_T}{\psi_T}
}
For Beryllium, the trial wavefunction is a product of the Slater determinant part 
and the correlation part, namely $\psi_T = \psi_D\psi_C$.

The product rule of differentiation gives us
\eq{
  \frac{\op\nabla^2 \psi_T}{\psi_T} = 
  \frac{\op\nabla^2 \psi_D}{\psi_D}
    +2 \frac{\op\nabla \psi_D}{\psi_D}\cdot\frac{\op\nabla \psi_C}{\psi_C}
    +\frac{\op\nabla^2 \psi_C}{\psi_C}
}

\subsection{Efficient Computation of the Slater Determinant}

For larger atoms, the evaluation of the gradient and the Laplacian of the Slater
determinant becomes increasingly numerically demanding
to compute. Computing these quantities with brute force, 
leads to $N\cdot d$ operations to find the determinant and thus
multiplying this with our $O(N^3)$ operations.
In the following, we derive a method that deals with this issue, 
and achieves a lower number of operations.

We can approximate the Slater determinant as
\eq{
	\Phi(\vec r_1, ..., \vec r_N) \propto \det\uparrow\cdot\det\downarrow
}
where the spin determinants are the determinants which only depend on spin up and spin down
respectively. The determinants are $2\times 2$ for Berylllium and $5\times 5$ for Neon.
This is true only if $\OP H$ is spin independent.

Then, $\det \op D = |\op D| = |\op D|_{\uparrow}\cdot |\op D|_{\downarrow}$, 
where the Slater matrices are dependent on the positions of the electrons. 
Each time we update the positions and differentiate the Slater determinant,
the Slater matrix is changed, but by calculating the determinant 
from scratch each time, we will certainly do unnecessary computations. 

This is solved by the following algorithm, that instead of calculating 
the determinant, updates the \textit{inverse} of the Slater matrix suitably.

We first express $(i,j)$ elements of the inverse of $\op D$ as
\eq{
  d_{ij}^{-1} = \frac{C_{ji}}{|\op D|}
}
where $C_{ji}$ is the transposed cofactor-matrix element of $\op D$.

This motivates the ratio
\eq{
  R \equiv \frac{|\op D(\vec r^{new})|_{\uparrow}}{|\op D(\vec r^{old})|_{\uparrow}} 
  = \frac{\sum_{j=1}^N d_{ij}^{new} C_{ij}^{new}}
    {\sum_{j=1}^N d_{ij}^{old} C_{ij}^{old}}
}
Every time we move particle $i$, the $i$-th row of $\op D$ changes,
and we have to update the inverse. However, the $i$-th row of $\op C$
is independent\footnote{Since the cofactor-matrix elements $c_{ij}$ is defined by 
removing $i$-th row and $j$-th column from a matrix $\op A$,
and then taking the determinant of the remaining matrix.} 
of the $i$-th row of $\op D$, which means that
we must have
\eq{
  \op C_{ij}^{new} = \op C_{ij}^{old} = (d_{ji}^{-1})^{old}\cdot |\op D| 
    \text{ for } j=1,...,N
}
and using
\eq{
  \sum_{k=1}^N d_{ik}\ d_{kj}^{-1} =\delta_{ij}
}
The result is
\eq{
  R=\sum_{j=1}^N d_{ij}^{new} (d_{ji}^{-1})^{old}
    =\sum_{j=1}^N \phi_j(\vec r_i^{new})\ d_{ji}^{-1} (\vec r_i^{old})
}

The algorithm for updating the inverse of the matrix 
when a new position is accepted is then

\begin{algorithm}
	\caption{Inverse of Slater Matrix}\label{algo1}
  \begin{algorithmic}[1]
    \Procedure{Update columns $j\neq i$}{}
    \For{each column $i\neq j$}
      \State{$ S_j = \sum_{l=1}^N d_{il}(\vec r^{new}) d_{lj}^{-1}(\vec r^{old}) $}
      \State{$ (d_{kj}^{-1})^{new} 
        = (d_{kj}^{-1})^{old} - \frac{S_j}{R}(d_{ki}^{-1})^{old} $} 
    \EndFor
    \EndProcedure
    \Procedure{Update column $i$}{}
      \State{$ (d_{ki}^{-1})^{new} 
        = \frac{1}{R}(d_{ki}^{-1})^{old} $}
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

We can then calculate the gradient and laplacian as
\eq{
  \frac{\op\nabla_k |\op D|}{|\op D|} 
    = \sum_{j=1}^N \nabla_k \phi_j(\vec r_i^{new})\ d_{ji}^{-1} (\vec r_i^{old})\\
  \frac{\op\nabla_k^2 |\op D|}{|\op D|} 
    = \sum_{j=1}^N \nabla_k^2 \phi_j(\vec r_i^{new})\ d_{ji}^{-1} (\vec r_i^{old})
}

REMEMBER TO SAY SOMETHING ABOUT NUMBER OF OPERATIONS.

\subsection{Introducing Gaussian-Type Orbitals}
In this project, we have shown how one can use Hydrogen-like wave functions as the basis
for the Slater determinant, and up until now, 
we have used so-called \textit{Slater-Type Orbitals} (STOs).
We will now replace the STOs with \textit{Gaussian-Type Orbitals} (GTOs).

The spin-factorized Slater determinants (one for spin up and one for spin down),
are given by
\eq{\psi_{D_{spin}} = 
  \vmat{\phi_1(\vec r_1)& \cdots & \phi_n(\vec r_1)\\
  \vdots&\ddots&\vdots\\
  \phi_1(\vec r_n)& \cdots & \phi_N(\vec r_n)}
}

where $n$ is equal to half the number of particles, 
and  $\phi_j(\vec r_i)$ are one-particle wave functions 
$\phi_{1s}$, $\phi_{2s}$ and $\phi_{2p(3)}$
($(3)$ is short-hand notation for the $x$, $y$ and $z$ parts).
These spin independent, one-particle wave functions are
linear combinations of basis functions, and we will now use \textit{contracted} GTOs
(CGTOs) for this purpose.

The functions can then be written as
\eq{\phi_j(\vec r_i) = \sum_p C_{pj} \varphi_p(\vec r_i)
}

The CGTOs are on the form
\eq{
  \varphi_p^{CGTO}(\vec r_i) = \sum_k N_k \varphi^{GTO}_k(\vec r_i)
}
with
\eq{
  \varphi^{GTO}_k = d_k x^m y^n z^o e^{-\alpha_k r^2}
}
which are called \textit{cartesian} GTOs. 
The numerical coefficients $\alpha_k$ and $d_k$ are chosen to optimalize the
basis functions, and we use values from the 
\textit{Environmental Molecular Science Laboratory} (EMSL) 
website\footnote{https://bse.pnl.gov/bse/portal}.

The normalization factors are given as\footnote{Ab Initio, p. 280}
\eq{
  N_k = \left(\frac{2\alpha_k}{\pi}\right)^{3/4}
  \sqrt{\frac{(4\alpha_k)^{m+n+o}}{(2m-1)!!(2n-1)!!(2o-1)!!}}
}
and since they are dependent on the total angular momentum,
given by the quantum numbers $l = m+n+o$, we will write them as
$N_k = N_{m,n,o}$.

\section{Results}

\appendix
\renewcommand{\thesubsection}{Appendix \Alph{subsection}:}
\renewcommand{\thesubsubsection}{\arabic{subsubsection}.}

\subsection{Mathematical Derivations}
%% The spherical nature of the wavefunction
The Laplace operator of a function $f$ in three dimensions, $\nabla^2 f$,
can be represented as
{\small
\eq{
  \bigg( \frac{\partial^2}{\partial r^2} 
    + \frac{2}{r} \frac{\partial}{\partial r} \bigg) f
    +\frac{1}{r^2 \sin\theta}\frac{\partial}{\partial \theta}
    \bigg( \sin\theta \frac{\partial}{\partial \theta}  \bigg) f
    +\frac{1}{r^2 \sin^2\theta}\frac{\partial^2}{\partial^2 \varphi} f
}}%

in spherical coordinates, and as

{\small
\eq{
	\bigg( 
	\frac{\partial}{\partial x^2} +
	\frac{\partial}{\partial y^2} +
	\frac{\partial}{\partial z^2}
	\bigg) f
}}%

in cartesian coordinates.
\subsubsection{The wavefunction of Beryllium}
We start by finding the first and second derivative of the determinant part,
which are only dependent on the radii of the particles. This means that the gradient can be written 
\eq{
  \op\nabla f = \unit r \frac{\partial f}{\partial r}
  \;\text{ and }\;
  \op\nabla^2 f = \frac{\partial^2 f}{\partial r^2} 
    + \frac{2}{r}\frac{\partial f}{\partial r}
}
where $\vec r = r\unit r$.
  
We define the functions
\eq{
  f_i &\equiv -\frac{\alpha r_i}{2}\\
  g_i &\equiv \exp(f_i)\\
  F_{ij} &\equiv \phi_{1s}(\vec r_i)\phi_{2s}(\vec r_j)
  -\phi_{1s}(\vec r_j)\phi_{2s}(\vec r_i)
}
and use them to simplify derivatives 
of the Hydrogen-like wavefunctions in the following way
\eq{
  \phi_{1s}^i &= g_i^2\\
  \frac{\partial \phi_{1s}^i}{\partial r_i} &= -\alpha g_i^2\\
  \frac{\partial^2 \phi_{1s}^i}{\partial r_i^2} &= \alpha^2 g_i^2\\
  \phi_{2s}^i &= g_i(1+f_i)\\
  \frac{\partial \phi_{2s}^i}{\partial r_i} &= -\alpha g_i(1+f_i/2)\\
  \frac{\partial^2 \phi_{2s}^i}{\partial r_i^2} &= \frac{3\alpha^2}{4} g_i(1+f_i/3)
  }
  and for the $2p$ part we need to differentiate in cartesian coordinates,
  since the Hydrogenic wave function is dependant on the
  angles, thus
  \eq{
  \phi_{2p_k}^i &= \alpha k_i g_i \text{ for } k_i = x_i,y_i,z_i\\
  \frac{\partial\phi_{2p_x}^i}{\partial x_i} 
    &= \left(\alpha - \frac{\alpha^2 x_i^2}{2 r_i} \right)g_i\\
  \frac{\partial\phi_{2p_x}^i}{\partial y_i} 
    &=-\frac{\alpha^2 x_i y_i }{2 r_i} g_i\\ 
  \frac{\partial\phi_{2p_x}^i}{\partial z_i} 
    &=-\frac{\alpha^2 x_i z_i}{2 r_i} g_i
}

which gives us a gradient on the form

\eq{
  \nabla \phi_{2p_x}^i = 
  \left(
  \alpha g_i - \frac{\alpha^2 x_i^2}{2 r_i}g_i,
    -\frac{\alpha^2 x_i y_i }{2 r_i} g_i,
    -\frac{\alpha^2 x_i z_i}{2 r_i} g_i
  \right)
}
The expressions for $\phi_{2p_y}$ and $\phi_{2p_z}$ are similarly
\eq{
  \nabla \phi_{2p_y}^i &= 
  \left(
  \frac{\alpha^2 x_i y_i}{2 r_i}g_i,
    \alpha g_i -\frac{\alpha^2 y_i^2 }{2 r_i} g_i,
    -\frac{\alpha^2 y_i z_i}{2 r_i} g_i
  \right)\\
  \nabla \phi_{2p_z}^i &= 
  \left(
  -\frac{\alpha^2 x_i z_i}{2 r_i}g_i,
    -\frac{\alpha^2 y_i z_i}{2 r_i} g_i,
    \alpha g_i -\frac{\alpha^2 z_i^2}{2 r_i} g_i
  \right)
}

Then the terms required to calculate the Slater determinant
\eq{
  F_{ij} &= g_i^2 (1+f_j)g_j - g_j^2 (1+f_i)g_i\\
  \frac{\partial F_{ij}}{\partial r_i} 
    &= -\alpha g_i g_j (g_i(1+f_j) - g_j (1+f_i/2))\\
  \frac{\partial^2 F_{ij}}{\partial r_i^2} 
    &= \alpha^2 g_i g_j (g_i(1+f_j) - \frac{3}{4} g_j (1+f_i/3))\\
  \frac{\partial F_{ij}}{\partial r_j} 
    &= \alpha g_i g_j (g_j(1+f_i) - g_i (1+f_j/2))\\
  \frac{\partial^2 F_{ij}}{\partial r_j^2} 
    &= -\alpha^2 g_i g_j (g_j(1+f_i) - \frac{3}{4} g_i (1+f_j/3))\\
}
The determinant part is
\eq{
  \psi_D = F_{12}F_{34}
}
where the first is only affected by differentiation with respect to particle 1 or 2,
and opposite for the second part
\eq{
  \mat{
    \frac{\op\nabla_1 \psi_D}{\psi_D} = \frac{\op\nabla_1 F_{12}}{F_{12}} &
    \frac{\op\nabla_2 \psi_D}{\psi_D} = \frac{\op\nabla_2 F_{12}}{F_{12}} \\\\
    \frac{\op\nabla_3 \psi_D}{\psi_D} = \frac{\op\nabla_3 F_{34}}{F_{34}} &
    \frac{\op\nabla_4 \psi_D}{\psi_D} = \frac{\op\nabla_4 F_{34}}{F_{34}}
  }
}
The result is two different quantities
\eq{
  \frac{\op\nabla_k \psi_D}{\psi_D} =
  \begin{cases}
    \frac{\op\nabla_i F_{ij}}{F_{ij}}
    &= -\alpha \frac{\vec r_i}{r_i} \frac{(g_i(1+f_j) 
      - g_j (1+f_i/2))}{g_i (1+f_j) - g_j (1+f_i)}
    ,\text{ if } k=i=j-1 \\\\
    \frac{\op\nabla_j F_{ij}}{F_{ij}}
    &= -\alpha \frac{\vec r_j}{r_j}\frac{(g_i (1+f_j/2) 
      - g_j(1+f_i))}{g_i (1+f_j) - g_j (1+f_i)}
    ,\text{ if } k=j=i+1
  \end{cases}
}
one for particles 1 and 3, and one for 2 and 4, where $i\in {1,3}$ and $j\in {2,4}$.

For the second derivative part, we have 
\eq{
  \frac{\op\nabla_k^2 \psi_D}{\psi_D} =
  \begin{cases}
    \frac{\op\nabla_i^2 F_{ij}}{F_{ij}}
    &= \frac{\alpha^2 (g_i(1+f_j) 
      - \frac{3}{4} g_j (1+f_i/3)) - \frac{2\alpha}{r}(g_i(1+f_j) - g_j (1+f_i/2))}
      {g_i (1+f_j) - g_j (1+f_i)}\\\\
    \frac{\op\nabla_j^2 F_{ij}}{F_{ij}}
    &= \frac{\alpha^2 (\frac{3}{4}g_i(1+f_j/3) 
      - g_j (1+f_i)) - \frac{2\alpha}{r}(g_i (1+f_j/2) 
      - g_j(1+f_i))}
      {g_i (1+f_j) - g_j (1+f_i)}
  \end{cases}
}
with the same conditions as above.
Now we move on to the calculation of the correlation parts,
given by the function in (\ref{psiC}). 

First off, we define
\eq{
  f_{ij} \equiv \frac{ar_{ij}}{1+\beta r_{ij}}
}
with the corresponding derivatives (with respect to $r_{ij}$)
\eq{
  f_{ij}' &= \frac{a}{(1+\beta r_{ij})^2}\\
  f_{ij}'' &= \frac{-2a\beta}{(1+\beta r_{ij})^3}
}

The gradient of the wavefunction, 
divided by the wavefunction, for particle $k$ in the $x$-direction is then
\eq{
  \left[\frac{\op\nabla_k\psi_C}{\psi_C}\right]_x 
  =\frac{1}{\psi_C}\frac{\partial\psi_C}{\partial x_k}
}
If we look at the first derivative in the $x$-direction, 
we see that the parts of the wavefunction that is not dependent on $k$, 
will remain unaffected by the 
differentiation.
When we split the expression for $i<k$ and $k>i$, we get that
\equ{
  \frac{\partial\psi_C}{\partial x_k}&=\prod_{i,j\neq k} g_{ij}
    \frac{\partial}{\partial x_k}
    \left[ \prod_{i<k} g_{ik} \cdot \prod_{i>k} g_{ki} \right]\nonumber\\
    &=\prod_{i,j\neq k} g_{ij}
      \left[\prod_{i>k} g_{ki}\frac{\partial}{\partial x_k}\prod_{i<k} g_{ik} 
      + \prod_{i<k} g_{ik} \frac{\partial}{\partial x_k}\prod_{i>k} g_{ki} \right]
      \nonumber\\
    &=\prod_{i,j\neq k} g_{ij}
      \left[\prod_{i>k} g_{ki} \sum_{i<k} \frac{\partial g_{ik}}{\partial x_k} \prod_{p\neq i} g_{pi}
      + \prod_{i<k} g_{ik} \sum_{i>k} \frac{\partial g_{ki}}{\partial x_k} \prod_{q\neq i} g_{iq} \right]
      \nonumber\\
    &=\prod_{i<j} g_{ij}
      \left[\frac{1}{\prod_{i<k} g_{ik}} \sum_{i<k} 
      \frac{\partial g_{ik}}{\partial x_k} \prod_{p\neq i} g_{pi}
      + \frac{1}{\prod_{i>k} g_{ki}} \sum_{i>k} 
      \frac{\partial g_{ki}}{\partial x_k} \prod_{p\neq i} g_{pi} \right]
      \nonumber\\
    &=\psi_C
      \left[\sum_{i<k} \frac{1}{g_{ik}} \frac{\partial g_{ik}}{\partial x_k}
      +\sum_{i>k} \frac{1}{g_{ki}} \frac{\partial g_{ki}}{\partial x_k} \right]
      \label{DpsiC}
}
Here we factorized the wavefunction outside the expression, 
and noticed that the only part that doesn't cancel is the $ik$-th and $ki$-th
in the sums.

Dividing by the wavefunction, we get
\eq{
  \left[\frac{\op\nabla_k\psi_C}{\psi_C}\right]_x
  &=\sum_{i=1}^{k-1}\frac{1}{g_{ik}}\frac{\partial g_{ik}}{\partial x_k}  
  + \sum_{i=k+1}^{N}\frac{1}{g_{ki}}\frac{\partial g_{ki}}{\partial x_k} \\
  &=\sum_{i=1}^{k-1}\frac{\partial f_{ik}}{\partial x_k}  
  - \sum_{i=k+1}^{N}\frac{\partial f_{ki}}{\partial x_i}\\
  &=\sum_{i=1}^{k-1}\frac{x_k-x_i}{r_{ik}}\frac{\partial f_{ik}}{\partial r_{ik}}  
  - \sum_{i=k+1}^{N}\frac{x_i-x_k}{r_{ki}}\frac{\partial f_{ki}}{\partial r_{ki}}
}
since $g_{ij}$ is an exponential function, so
$\sfrac{\partial g_{ij}}{\partial x_i} = g_{ij} \sfrac{\partial f_{ij}}{\partial x_j}$.
We also used the fact that $\sfrac{\partial g_{ij}}{\partial x_i} = \sfrac{-\partial g_{ij}}{\partial x_j}$ to differentiate with respect to the second index in both of the sums.
Finally, we have used the chain rule to attain an expression that is dependent
on the distance between the two particles
\eq{
  \frac{\partial f_{ij}}{\partial x_j} 
  = \frac{\partial f_{ij}}{\partial r_{ij}} \frac{\partial r_{ij}}{\partial x_j} 
  = \frac{x_j - x_i}{r_{ij}} \frac{\partial f_{ij}}{\partial r_{ij}}
}
Thus
\eq{
  \frac{\op\nabla_k\psi_C}{\psi_C} &=
    \sum_{i=1}^{k-1}\frac{\vec r_{ik}}{r_{ik}}\frac{\partial f_{ik}}{\partial r_{ik}}  
    - \sum_{i=k+1}^{N}\frac{\vec r_{ki}}{r_{ki}}\frac{\partial f_{ki}}{\partial r_{ki}}\\
    &=\sum_{i=1}^{k-1}\frac{\vec r_{ik}}{r_{ik}}\frac{a}{(1+\beta r_{ik})^2}  
    - \sum_{i=k+1}^{N}\frac{\vec r_{ki}}{r_{ki}}\frac{a}{(1+\beta r_{ki})^2}\\
    &=\sum_{i\neq k}\frac{\vec r_{ik}}{r_{ik}}\frac{a}{(1+\beta r_{ik})^2} 
}

From (\ref{DpsiC}), we can gather that the double derivative part is described by
\eq{
  \left[\frac{\mathbf{\op\nabla}^2 \psi_C}{\psi_C}\right]_x
  &=\frac{1}{\psi_C}\frac{\partial}{\partial x_k}\left(\psi_C
      \left[\sum_{i<k} \frac{\partial f_{ik}}{\partial x_k}
      +\sum_{i>k} \frac{\partial f_{ki}}{\partial x_k} \right]\right)\\
  &=\left[\sum_{i<k} \frac{\partial^2 f_{ik}}{\partial x_k^2}
      +\sum_{i>k} \frac{\partial^2 f_{ki}}{\partial x_k^2} \right]
      +\frac{1}{\psi_C}\frac{\partial \psi_C}{\partial x_k}
      \left[\sum_{i<k} \frac{\partial f_{ik}}{\partial x_k}
      +\sum_{i>k} \frac{\partial f_{ki}}{\partial x_k} \right]\\
  &=\sum_{i\neq k}\frac{\partial^2 f_{ik}}{\partial x_k^2} +
    \left[\sum_{i=1}^{k-1}\frac{\partial f_{ik}}{\partial x_k} -
    \sum_{i=k+1}^{N}\frac{\partial f_{ki}}{\partial x_i}
    \right]^2\\
  &=\sum_{i\neq k}
    \frac{\partial}{\partial x_k}
    \left(
    \frac{\partial f_{ik}}{\partial r_{ik}}
    \frac{\partial r_{ik}}{\partial x_k}
    \right)+
    \left[\sum_{i\neq k}\frac{\partial r_{ik}}{\partial x_k}
    \frac{\partial f_{ik}}{\partial r_{ik}}
    \right]^2\\
  &=\sum_{i\neq k}
    \left[
    \frac{\partial r_{ik}}{\partial x_k}
    \frac{\partial}{\partial x_k}
    \frac{\partial f_{ik}}{\partial r_{ik}}
    +
    \frac{\partial f_{ik}}{\partial r_{ik}}
    \frac{\partial^2 r_{ik}}{\partial x_k^2}\right]
    +
    \left[\sum_{i\neq k}\frac{\partial r_{ik}}{\partial x_k} f_{ik}'
    \right]
    \left[\sum_{j\neq k}\frac{\partial r_{jk}}{\partial x_k} f_{jk}'
    \right]\\
  \left[\frac{\mathbf{\op\nabla}^2 \psi_C}{\psi_C}\right]_x
  &=\sum_{i\neq k}
    \left[
    \left(
    \frac{\partial r_{ik}}{\partial x_k}
    \right)^2
    f_{ik}''
    +
    f_{ik}'
    \frac{r_{ik}^2 - (x_k-x_i)^2}{r_{ik}^3}\right]
    \\&+
    \sum_{j\neq k}\left[\frac{\partial r_{ik}}{\partial x_k} f_{ik}'\left(
    \frac{\partial r_{ik}}{\partial x_k} f_{ik}'+
    \sum_{j\neq k,i} \frac{\partial r_{jk}}{\partial x_k} f_{jk}'\right)
    \right]\\
  \left[\frac{\mathbf{\op\nabla}^2 \psi_C}{\psi_C}\right]_x
  &=\sum_{i\neq k}
    \left[
    \left(
    \frac{\partial r_{ik}}{\partial x_k}
    \right)^2
    f_{ik}''
    +
    f_{ik}'
    \frac{r_{ik}^2 - (x_k-x_i)^2}{r_{ik}^3}\right]
    \\&+
    \sum_{j\neq k}\left[\left(\frac{\partial r_{ik}}{\partial x_k} f_{ik}'\right)^2
    +
    \sum_{j\neq k,i} \frac{\partial r_{ik}}{\partial x_k} f_{ik}'
    \frac{\partial r_{jk}}{\partial x_k} f_{jk}'
    \right]\\
  \left[\frac{\mathbf{\op\nabla}^2 \psi_C}{\psi_C}\right]_x
  &=\sum_{i\neq k}
    \left[
    \left(
    \frac{x_k-x_i}{r_{ik}}
    \right)^2
    f_{ik}''
    +
    f_{ik}'
    \frac{r_{ik}^2 - (x_k-x_i)^2}{r_{ik}^3}\right]
    \\&+
    \sum_{j\neq k}\left[\left(\frac{x_k-x_i}{r_{ik}} f_{ik}'\right)^2
    +
    \sum_{j\neq k,i} \frac{(x_k-x_i)(x_k-x_j)}{r_{ik} r_{jk}} 
    f_{ik}' f_{jk}'
    \right]\\
    \left[\frac{\mathbf{\op\nabla}^2 \psi_C}{\psi_C}\right]_x
  &=\sum_{i\neq k}
    \left[
    \left(
    \frac{x_k-x_i}{r_{ik}}
    \right)^2
    f_{ik}''
    +
    f_{ik}'
    \frac{r_{ik}^2 - (x_k-x_i)^2}{r_{ik}^3}\right]
    \\&+
    \sum_{i,j\neq k}\frac{(x_k-x_i)(x_k-x_j)}{r_{ik} r_{jk}} 
    f_{ik}' f_{jk}'\\
}
If we now sum up for all dimensions, we get 
\eq{
  \frac{\mathbf{\op\nabla}^2 \psi_C}{\psi_C}
  &=\sum_{i\neq k}
    \left[\frac{r_{ik}^2}{r_{ik}^2}
    f_{ik}''
    +
    f_{ik}'
    \frac{3r_{ik}^2 - r_{ik}^2}{r_{ik}^3}\right]
    +
    \sum_{i,j\neq k}\frac{(\vec r_k-\vec r_i)(\vec r_k-\vec r_j)}{r_{ik} r_{jk}} 
    f_{ik}' f_{jk}'\\
  &=\sum_{i\neq k}
    \left[f_{ik}''+ \frac{2}{r_{ik}}f_{ik}'\right]
    +
    \sum_{i,j\neq k}\frac{(\vec r_k-\vec r_i)(\vec r_k-\vec r_j)}{r_{ik} r_{jk}} 
    f_{ik}' f_{jk}'
}

\end{document}